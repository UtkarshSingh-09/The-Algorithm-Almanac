{
    "What is Machine Learning?": "Machine Learning is the science and art of programming computers so they can learn from data. It is the field of study that gives computers the ability to learn without being explicitly programmed. A program learns from experience E with respect to a task T and a performance measure P if its performance on T improves with E.",
    "What are the main types of Machine Learning systems?": "They can be classified as supervised, unsupervised, semisupervised, and reinforcement learning. Another dimension is batch vs. online learning, and instance-based vs. model-based learning.",
    "What are the main challenges in Machine Learning?": "Some key challenges are insufficient quantity of training data, nonrepresentative data, poor-quality data, irrelevant features, overfitting, and underfitting.",
    "What is overfitting, and how can you prevent it?": "Overfitting occurs when a model performs well on training data but fails on new data. Solutions include getting more training data, simplifying the model, using regularization, or applying cross-validation.",
    "What are the main steps in a Machine Learning project?": "Frame the problem, select a performance measure, obtain the data, explore and visualize it, prepare the data, select and train a model, fine-tune the model, present the solution, and deploy the system.",
    "Why is stratified sampling useful?": "It ensures that the train/test sets represent important categories proportionally, reducing bias compared to random sampling.",
    "What is cross-validation, and why is it useful?": "Cross-validation splits the training data into multiple folds to ensure the model generalizes well. It reduces variance in performance estimates.",
    "What is classification, and how is it different from regression?": "Classification predicts categories (spam/ham), while regression predicts continuous values (price of a house).",
    "What is a confusion matrix?": "A confusion matrix shows true positives, false positives, true negatives, and false negatives. It helps evaluate classification beyond accuracy.",
    "What are precision and recall?": "Precision is the ratio of true positives to all predicted positives, while recall is the ratio of true positives to all actual positives. They measure correctness and completeness respectively.",
    "What is the ROC curve?": "The ROC curve plots true positive rate vs. false positive rate. The area under the curve (AUC) indicates how well the classifier distinguishes classes.",
    "What is gradient descent?": "Gradient descent is an optimization algorithm that updates parameters iteratively in the direction of the negative gradient to minimize cost.",
    "What are batch, stochastic, and mini-batch gradient descent?": "Batch GD uses the full dataset per step, stochastic GD uses one instance at a time (with noise), and mini-batch GD uses small random batches (balance between the two).",
    "What is regularization?": "Regularization adds a penalty term to the cost function to reduce model complexity and prevent overfitting. Examples: L1 (Lasso), L2 (Ridge), Elastic Net.",
    "What is the kernel trick in SVMs?": "The kernel trick allows linear models to perform nonlinear classification by implicitly mapping data to higher dimensions without computing the mapping explicitly.",
    "What is soft margin classification?": "It allows some misclassifications in SVMs to handle noisy datasets, balancing margin width and classification errors.",
    "What is a decision tree, and how does it work?": "Decision trees split the data by asking a series of questions (on features) until a prediction can be made. Splits are chosen to maximize purity (minimize impurity).",
    "What are the advantages and disadvantages of decision trees?": "Advantages: easy to interpret, handle nonlinear data, require little preprocessing. Disadvantages: prone to overfitting, unstable (small data changes can alter the tree).",
    "What is the CART algorithm?": "CART (Classification and Regression Trees) recursively splits the training set into two subsets using the feature and threshold that minimize impurity. It is a greedy algorithm and does not guarantee the optimal tree.",
    "What is Gini impurity vs entropy?": "Both measure node impurity. Gini tends to isolate the most frequent class quickly, while entropy is more sensitive to rare classes. Both yield similar trees in practice.",
    "How can you regularize decision trees?": "By limiting max depth, min samples per leaf, min samples per split, or using max features. Pruning also reduces overfitting.",
    "What is ensemble learning?": "Ensemble learning combines predictions from multiple models (weak learners) to improve performance compared to a single model.",
    "What are bagging and pasting?": "Bagging trains models on random subsets of the data (with replacement), while pasting does so without replacement. Aggregated predictions reduce variance.",
    "What is a random forest?": "A random forest is an ensemble of decision trees trained on bootstrapped samples with feature randomness at each split. It improves generalization and reduces variance.",
    "What is boosting?": "Boosting trains models sequentially, where each model tries to correct the errors of its predecessor. Examples: AdaBoost, Gradient Boosting.",
    "What is stacking?": "Stacking combines multiple models’ predictions using another model (meta-learner) to achieve better results.",
    "What is dimensionality reduction?": "It reduces the number of features while preserving as much information as possible. It helps fight the curse of dimensionality, speeds training, and improves visualization.",
    "What is PCA?": "Principal Component Analysis projects data onto lower dimensions while maximizing variance. It finds principal components that capture most of the dataset’s variability.",
    "What is Kernel PCA?": "Kernel PCA uses kernels to perform nonlinear dimensionality reduction, useful when data is not linearly separable.",
    "What is LLE (Locally Linear Embedding)?": "LLE is a manifold learning technique that preserves local relationships in data while reducing dimensions.",
    "What is clustering?": "Clustering groups similar data points without labels. Algorithms include k-means, DBSCAN, and hierarchical clustering.",
    "What are the limitations of k-means?": "K-means assumes spherical clusters of similar sizes, struggles with outliers, and requires knowing the number of clusters in advance.",
    "What is DBSCAN?": "DBSCAN is a density-based clustering algorithm that can find arbitrarily shaped clusters and detect noise without requiring the number of clusters.",
    "What are Gaussian Mixture Models (GMMs)?": "GMMs assume data is generated from a mixture of several Gaussian distributions. They are more flexible than k-means and can model elliptical clusters.",
    "What is anomaly detection?": "It identifies unusual data points that don’t conform to the general pattern. Used in fraud detection, intrusion detection, etc.",
    "What is an artificial neuron?": "It is a simplified mathematical model of a biological neuron. It computes a weighted sum of inputs plus a bias, then applies an activation function.",
    "What is a perceptron?": "A perceptron is a single-layer neural network model introduced by Rosenblatt. It can perform linear classification using a step activation function.",
    "What is a multilayer perceptron (MLP)?": "An MLP is a feedforward neural network with one or more hidden layers. It uses backpropagation to train and can model complex nonlinear relationships.",
    "What are the main Keras APIs?": "Sequential API for simple models, Functional API for complex DAGs, and Subclassing API for dynamic models.",
    "What are callbacks in Keras?": "Callbacks are functions executed during training, such as EarlyStopping, ModelCheckpoint, or TensorBoard logging.",
    "What are key hyperparameters in neural networks?": "Number of hidden layers, neurons per layer, learning rate, batch size, activation functions, weight initialization, and regularization methods.",
    "What are the Vanishing/Exploding Gradients Problems?": "These are problems where gradients grow exponentially larger (exploding) or smaller (vanishing) with each layer during backpropagation in deep neural networks. Vanishing gradients can cause learning to become very slow or stop altogether, while exploding gradients can make training unstable.",
    "What is Glorot and He Initialization?": "These are popular weight initialization strategies designed to mitigate the vanishing/exploding gradients problem. They set the initial random weights of a network's layers based on the number of input and output neurons (fan-in and fan-out), helping to keep the signal flowing properly through the network.",
    "What are Nonsaturating Activation Functions?": "These are activation functions, like ReLU (Rectified Linear Unit) and its variants (Leaky ReLU, ELU), that do not saturate for positive values. Unlike sigmoid or tanh functions that flatten out, these functions help to prevent the vanishing gradient problem by not having a zero gradient for a large range of inputs.",
    "What is Batch Normalization?": "Batch Normalization is a technique that normalizes the inputs of each layer for each mini-batch during training. It helps to speed up training, allows for higher learning rates, and acts as a regularizer, reducing the need for other techniques like Dropout.",
    "What is Gradient Clipping?": "Gradient Clipping is a technique used to prevent the exploding gradient problem. It involves capping the gradient values to a certain threshold during backpropagation, ensuring they do not become excessively large and destabilize the training process.",
    "What is Transfer Learning?": "Transfer Learning is a method where a model developed for a task is reused as the starting point for a model on a second task. It involves taking a pretrained network (trained on a large dataset like ImageNet) and fine-tuning its layers for a new, often smaller, dataset.",
    "What are some Faster Optimizers?": "Faster optimizers are algorithms that adapt the learning rate during training to achieve convergence more quickly than standard Gradient Descent. Examples include Momentum, Nesterov Accelerated Gradient (NAG), AdaGrad, RMSProp, and Adam, which is one of the most popular and effective optimizers.",
    "What is Learning Rate Scheduling?": "Learning Rate Scheduling is a technique that involves gradually reducing the learning rate during training. Starting with a larger learning rate and making it smaller as training progresses can help the model converge faster and more reliably to a good solution.",
    "How does Regularization help avoid Overfitting?": "Regularization techniques add a penalty to the loss function to discourage the model from becoming too complex and fitting the noise in the training data. Common methods include L1 and L2 regularization, Dropout (randomly turning off neurons during training), and Max-Norm regularization (constraining the weights of the network).",
    "What are Tensors in TensorFlow?": "A Tensor is the primary data structure in TensorFlow. It is a multi-dimensional array, similar to a NumPy ndarray, that can represent scalars, vectors, matrices, or higher-dimensional data. Tensors are the fundamental building blocks for all computations in TensorFlow.",
    "What is a Custom Loss Function?": "A custom loss function is a user-defined function that calculates the error or 'loss' between the model's predictions and the true labels. This allows for more flexibility than the standard built-in loss functions, enabling the model to optimize for a specific, unique objective.",
    "What is Autodiff in TensorFlow?": "Autodiff, or automatic differentiation, is a core feature of TensorFlow that automatically computes the gradients of computations. TensorFlow tracks operations on tensors to build a computation graph, and then uses this graph to calculate gradients with respect to any variable, which is essential for training models via backpropagation.",
    "What is a Custom Training Loop?": "A custom training loop provides fine-grained control over the training process, beyond what is offered by the standard `model.fit()` method in Keras. It allows you to manually iterate over datasets, calculate gradients, update model weights, and implement complex training procedures that are not supported by default.",
    "What is the TensorFlow Data API (tf.data)?": "The `tf.data` API is a powerful and efficient tool for building complex input pipelines for TensorFlow models. It allows you to load data from various sources, apply transformations like mapping and shuffling, and create batches of data to be fed into your model during training.",
    "What is the TFRecord Format?": "TFRecord is a simple, record-oriented binary format for storing a sequence of binary records. It is TensorFlow's recommended format for storing and reading large datasets efficiently, as it allows for data to be streamed from disk without loading the entire file into memory.",
    "How can you preprocess input features in TensorFlow?": "TensorFlow provides various tools for preprocessing. Categorical features can be encoded using one-hot vectors or embeddings. Keras Preprocessing Layers offer a convenient way to build preprocessing logic directly into your model, handling tasks like text vectorization, normalization, and discretization.",
    "What is the TensorFlow Datasets (TFDS) Project?": "TensorFlow Datasets is a collection of ready-to-use datasets that are already prepared in the `tf.data.Dataset` format. It provides easy access to dozens of popular public datasets, simplifying the process of downloading, parsing, and preparing data for use in TensorFlow.",
    "What is a Convolutional Layer?": "A convolutional layer is the core building block of a Convolutional Neural Network (CNN). It applies a set of learnable filters (or kernels) to the input image. Each filter slides over the input, computing dot products to create a feature map that highlights specific patterns like edges, corners, or textures.",
    "What is a Pooling Layer?": "A pooling layer is used to progressively reduce the spatial size (width and height) of the representation, which helps to decrease the number of parameters and computation in the network. The most common type is Max Pooling, which takes the maximum value from a small grid of the feature map.",
    "What are some famous CNN Architectures?": "Famous CNN architectures that have achieved state-of-the-art performance on image recognition tasks include LeNet-5 (one of the earliest), AlexNet (a deep CNN that won the 2012 ImageNet challenge), GoogLeNet (which introduced the 'inception module'), and ResNet (which uses 'residual connections' to train very deep networks).",
    "What is Object Detection?": "Object detection is a computer vision task that involves identifying and locating objects within an image or video. It goes beyond simple classification by drawing a bounding box around each detected object and assigning a class label to it. Popular algorithms include YOLO (You Only Look Once) and SSD (Single Shot Detector).",
    "What is Semantic Segmentation?": "Semantic segmentation is a computer vision task where every pixel in an image is classified into a category. Unlike object detection which uses bounding boxes, semantic segmentation creates a pixel-wise mask for each object, providing a more detailed understanding of the image content.",
    "What are Recurrent Neural Networks (RNNs)?": "Recurrent Neural Networks are a type of neural network designed to work with sequence data, such as text or time series. They have loops in them, allowing information to persist. A recurrent neuron receives inputs from the current time step and also from its own output from the previous time step.",
    "How are RNNs trained?": "RNNs are typically trained using a variation of backpropagation called Backpropagation Through Time (BPTT). The network is 'unrolled' through all the time steps, creating a very deep feedforward network, and then standard backpropagation is applied to update the weights.",
    "How can you forecast a Time Series with RNNs?": "To forecast a time series, you can train an RNN to predict the next value (or values) in a sequence given the previous values. The model learns the temporal patterns in the data. Once trained, you can feed it a sequence of recent values to predict future values one step at a time.",
    "What are some challenges with handling long sequences in RNNs?": "The main challenge with long sequences is that the short-term memory of a basic RNN is limited. Gradients can vanish or explode during BPTT over many time steps, making it difficult for the network to learn long-range dependencies. More advanced architectures like LSTMs (Long Short-Term Memory) and GRUs (Gated Recurrent Units) were developed to address this issue.",
    "What is an Encoder-Decoder Network?": "An Encoder-Decoder network is a type of RNN architecture used for sequence-to-sequence (seq2seq) tasks like machine translation. The encoder RNN processes the input sequence and compresses it into a fixed-size context vector. The decoder RNN then takes this context vector and generates the output sequence one step at a time.",
    "What is the Attention Mechanism?": "The Attention Mechanism improves upon the basic Encoder-Decoder model by allowing the decoder to look at all parts of the input sequence at each step of the output generation. It learns to pay 'attention' to the most relevant input words when generating a particular output word, overcoming the bottleneck of a fixed-size context vector.",
    "What is a Transformer model?": "The Transformer is a novel network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. It processes all input tokens simultaneously and uses self-attention to weigh the importance of different words in the input sequence. It has become the state-of-the-art for many NLP tasks.",
    "What is the difference between Positional Encoding and Word Embeddings?": "Word Embeddings represent words as dense vectors, capturing their semantic meaning, but they do not contain information about the word's position in a sentence. Positional Encodings are vectors that are added to the embeddings to give the model information about the order of the words in the sequence, which is crucial for the Transformer model as it has no recurrent or convolutional layers.",
    "What is an Autoencoder?": "An autoencoder is a type of artificial neural network used for unsupervised learning of efficient data codings. It consists of two parts: an encoder that compresses the input into a low-dimensional 'latent space' representation, and a decoder that reconstructs the input from this representation. They are used for dimensionality reduction, feature learning, and generative modeling.",
    "What are Generative Adversarial Networks (GANs)?": "A GAN is a class of machine learning frameworks where two neural networks, a Generator and a Discriminator, are trained simultaneously in a zero-sum game. The Generator's job is to create fake data that looks real, while the Discriminator's job is to distinguish between real and fake data. This adversarial process results in the generator producing increasingly realistic data.",
    "What is the difference between a Variational Autoencoder (VAE) and a standard Autoencoder?": "While a standard autoencoder learns a deterministic mapping to a latent space, a VAE learns the parameters of a probability distribution for the latent space. This means a VAE is generative; you can sample from the learned distribution to generate new data that resembles the training data.",
    "What is Style Transfer?": "Style Transfer is a technique that takes two images—a content image and a style reference image—and blends them together so the output image retains the content of the first image but is 'painted' in the style of the second. This is often achieved using the feature representations learned by a pretrained convolutional neural network.",
    "What is Reinforcement Learning (RL)?": "Reinforcement Learning is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. The agent learns by trial and error, receiving feedback in the form of rewards or punishments for its actions.",
    "What is a Policy in RL?": "A policy defines the learning agent's way of behaving at a given time. It's a mapping from perceived states of the environment to actions to be taken when in those states. The goal of RL is to find an optimal policy that maximizes the total expected reward.",
    "What is Q-Learning?": "Q-Learning is a model-free reinforcement learning algorithm. It aims to learn a policy by learning a Q-function that estimates the value (quality) of taking a certain action in a certain state. It can find an optimal action-selection policy for any given finite Markov decision process.",
    "What is Deep Q-Learning (DQN)?": "Deep Q-Learning combines Q-Learning with deep neural networks. Instead of using a table to store Q-values for every state-action pair, a neural network is used to approximate the Q-value function. This allows the algorithm to handle high-dimensional state spaces, such as the pixels of a game screen.",
    "How can you train a model on multiple GPUs?": "TensorFlow's Distribution Strategies, like `MirroredStrategy`, make it easy to distribute training across multiple GPUs on a single machine. The model's variables are mirrored across all GPUs, and gradients are aggregated and applied to all mirrors during each training step, effectively parallelizing the computation.",
    "What is TensorFlow Serving?": "TensorFlow Serving is a flexible, high-performance serving system for machine learning models, designed for production environments. It allows you to safely deploy new models and run experiments while keeping the same server architecture and APIs. It handles model versioning and can serve multiple models simultaneously.",
    "What is TFLite?": "TensorFlow Lite (TFLite) is a set of tools that enables on-device machine learning by helping developers run their models on mobile, embedded, and IoT devices. It converts a trained TensorFlow model into a special format that is optimized for speed and small binary size.",
    "What is TensorFlow.js?": "TensorFlow.js is a JavaScript library for training and deploying machine learning models in the browser and on Node.js. It allows you to build and train models directly in JavaScript and also run existing Python-trained TensorFlow models in a web environment.",
    "What are the main differences between TensorFlow 1 and TensorFlow 2?": "The biggest change in TensorFlow 2 is the switch to 'eager execution' by default, which makes it more intuitive and easier to debug, similar to standard Python. Keras is now the official high-level API, and many redundant APIs have been cleaned up or removed. Static graphs are still available for performance optimization via `tf.function`.",
    "What is a `tf.function`?": "A `tf.function` is a decorator in TensorFlow 2 that compiles a Python function into a callable TensorFlow graph. This allows for the performance benefits of graph-based execution (like optimizations and portability) while still allowing for the flexibility and ease-of-use of writing code in an eager, Pythonic style.",
    "How does data loading differ in TF2?": "The `tf.data` API is the recommended way to build efficient input pipelines in TensorFlow 2. It provides a flexible and high-performance way to load and preprocess data from various sources, and it integrates seamlessly with Keras and custom training loops.",
    "What is the role of Keras in TensorFlow 2?": "In TensorFlow 2, Keras has been adopted as the official high-level API for building and training models. It provides a simple, consistent interface for defining layers, building models, and running training loops, making it much easier for developers to get started with deep learning.",
    "What is the first step in an ML project checklist?": "The first step is to frame the problem and look at the big picture. This involves defining the business objective, determining how the model's performance will be measured, and checking for any existing solutions.",
    "What should you do after framing the problem?": "After framing the problem, you should get the data. This involves finding and documenting where to get the data, checking legal and authorization requirements, and converting the data to a format you can easily manipulate.",
    "What comes after getting the data?": "The next step is to explore the data to gain insights. This involves creating a copy of the data for exploration, studying each attribute, visualizing the data, and identifying potential correlations between attributes.",
    "What is the data preparation phase?": "This phase, also known as data cleaning, involves writing functions for all data transformations. You should fix or remove outliers, fill in missing values, and perform feature selection and engineering.",
    "What is the final step before launching the model?": "Before launching, you need to present your solution. This involves highlighting the big picture, explaining what worked and what did not, and documenting everything. After that, you can launch, monitor, and maintain your system.",
    "What is the kernel trick in SVMs?": "The kernel trick is a method that allows Support Vector Machines (SVMs) to operate in a high-dimensional feature space without explicitly computing the coordinates of the data in that space. It uses a kernel function to compute the dot product of the images of the data points in the feature space, enabling the learning of nonlinear decision boundaries.",
    "What is an RBF Kernel?": "The Radial Basis Function (RBF) kernel is a popular kernel function used in SVMs for nonlinear classification. It can be seen as creating a similarity measure between two points, where the similarity decreases with distance. It is very flexible and can create complex decision boundaries.",
    "How do you train and tune an SVM?": "Training an SVM involves finding the optimal hyperplane that separates the classes. This is a convex optimization problem. Tuning an SVM often involves using grid search with cross-validation to find the best hyperparameters, such as the regularization parameter C and the kernel-specific parameters (like gamma for the RBF kernel).",
    "What is Forward-Mode Autodiff?": "Forward-mode automatic differentiation computes the derivative of a function by traversing the computation graph from inputs to outputs. It computes the derivative of each operation as it goes. It is efficient when the number of inputs is smaller than the number of outputs.",
    "What is Reverse-Mode Autodiff?": "Reverse-mode automatic differentiation, which is used by backpropagation, traverses the computation graph from the final output back to the inputs. It first computes the output and then works backward to compute the gradients of the output with respect to the inputs. It is highly efficient when there are many inputs and few outputs, which is typical in neural networks.",
    "Why is Reverse-Mode Autodiff used in Deep Learning?": "Reverse-mode autodiff is used in deep learning because neural networks have a very large number of parameters (inputs to the loss function) and typically a single output (the loss). Reverse-mode can compute all the gradients with respect to the parameters in just two passes through the graph (one forward, one backward), making it much more computationally efficient than forward-mode for this type of problem.",
    "What is a Siamese Network?": "A Siamese Network is an architecture that contains two or more identical subnetworks. These subnetworks share the same weights and architecture. The goal is to learn an embedding space where similar inputs are placed close together. They are often used for tasks like signature verification, face recognition, and finding similar items.",
    "What is a Transformer-XL?": "Transformer-XL (Extra Long) is an evolution of the Transformer architecture designed to better handle long-term dependencies in sequence data. It introduces two main innovations: a recurrence mechanism that allows the model to reuse hidden states from previous segments, and a relative positional encoding scheme that captures positional information more effectively across segments.",
    "What is an Extreme Learning Machine (ELM)?": "An Extreme Learning Machine is a type of feedforward neural network where the weights of the hidden layer are not trained but are randomly assigned and fixed. Only the weights of the output layer are learned. This makes the training process extremely fast, though it may not always achieve the same performance as a fully trained network.",
    "What are Ragged Tensors?": "A ragged tensor is a tensor with one or more ragged dimensions, which are dimensions whose slices may have different lengths. For example, it can be used to store a batch of sentences where each sentence has a different number of words. TensorFlow provides `tf.RaggedTensor` to handle such data efficiently.",
    "What are Sparse Tensors?": "A sparse tensor is a tensor that is very sparsely populated with non-zero values. Instead of storing all the zero values, a sparse tensor efficiently stores only the non-zero elements and their indices. This is very useful for saving memory and computation when dealing with data like large embedding matrices where most entries are zero. TensorFlow provides `tf.SparseTensor` for this purpose.",
    "What are Tensor Arrays?": "A `tf.TensorArray` is a list of tensors. It has a dynamic size and can be used within a TensorFlow graph, especially inside loops created with `tf.while_loop`. They are useful for accumulating results in a dynamic way during graph execution.",
    "What are Sets in TensorFlow?": "TensorFlow provides operations to handle sets represented as 2D tensors. You can perform operations like computing the union, intersection, and difference between sets of data. These are represented by `tf.sets` and operate on `SparseTensor` objects."
}